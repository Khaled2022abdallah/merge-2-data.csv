{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "F-urRj6lZZKZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "# Read true and fake news datasets\n",
        "true_news = pd.read_csv('/content/True.csv')[['text']]\n",
        "fake_news = pd.read_csv('/content/Fake.csv')[['text']]\n",
        "\n",
        "max_sentence_len = 200\n",
        "\n",
        "def tokenize_and_clean(news, label):\n",
        "    # remove short text\n",
        "    news = news.loc[news['text'].str.len() > 1].copy()\n",
        "    # generate labels for each document\n",
        "    news['label'] = label\n",
        "    # taking only first 100 words from each document to semplify this notebook complexity\n",
        "    news['text'] = news['text'].apply(lambda x: remove_stopwords(x).split()[:max_sentence_len])\n",
        "    return news\n",
        "\n",
        "true_news = tokenize_and_clean(true_news, 0)\n",
        "fake_news = tokenize_and_clean(fake_news, 1)\n",
        "\n",
        "# merge the two dataframes\n",
        "dataset = true_news.append(fake_news)\n",
        "display(dataset)\n",
        "\n",
        "print(f\"There are {len(true_news)} negative class entries and {len(fake_news)} positive class entries - \" \n",
        "      f\"for a total of {len(true_news)+len(fake_news)} entries\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-GhOaae-6fhh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}